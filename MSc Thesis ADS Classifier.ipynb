{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# MSc Thesis Applied Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the sensitive source of the data, the data will not be presented in this notebook nor in the repo. This code is used to train the classifier presented in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch, evaluate, re\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device( \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('dataset')\n",
    "\n",
    "# Preprocess Data\n",
    "label_names = ['Niets', 'Dehumaniserend', 'Demoniserend', '(Gewelds)bedreiging', 'Doodsbedreiging', 'Elite-complot']\n",
    "\n",
    "def l2t(label: int):\n",
    "    return label_names[label]\n",
    "\n",
    "def t2l(label_text: str):\n",
    "    return label_names.index(label_text)\n",
    "\n",
    "def clean_labels(labels,\n",
    "                 convert_labels = False):\n",
    "    \"\"\"Takes labels in doccano format and returns a list of individual text labels, optionally as int labels\"\"\"\n",
    "    #Check if label is given, otherwise assign label 'Niets'\n",
    "    if labels is None:\n",
    "        labels = 'Niets'\n",
    "\n",
    "    #Split labels into list\n",
    "    split_labels = labels.split('#')\n",
    "    if convert_labels:\n",
    "        return [t2l(lab) for lab in split_labels]\n",
    "    else:\n",
    "        return split_labels\n",
    "    \n",
    "def preproc_message(text: str):\n",
    "    \"\"\"\n",
    "    Preprocess a text message by performing the following:\n",
    "    - Remove hyperlinks.\n",
    "    - Replace excessive quotation marks (\"\") with a single quote.\n",
    "    - Replace @mentions with @user.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'(http|https|ftp|www|\\w+\\.\\w+/)\\S+', '', text)  # Remove hyperlinks\n",
    "    text = re.sub(r'\"{2,}', '\"', text)  # Replace excessive quotation marks\n",
    "    text = re.sub(r'@\\S+', '@user', text)  # Replace @mentions\n",
    "    return text\n",
    "\n",
    "# Clean the tweets\n",
    "df['text'] = df['text'].apply(preproc_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=123)\n",
    "X, Y = df[['text']], df[['label']]  # Select 'text' and 'label' columns\n",
    "reX, reY = rus.fit_resample(X, Y)\n",
    "\n",
    "dfRe = pd.DataFrame({'text': reX['text'], 'label': reY['label']})\n",
    "dfRe = dfRe.dropna(axis=0)\n",
    "dfRe['label'] = dfRe['label'].astype(int)\n",
    "dataset = Dataset.from_pandas(dfRe[['id','text','label']], preserve_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = dataset.train_test_split(test_size=0.25, seed=123)\n",
    "valData = trainData['test'].train_test_split(test_size=0.6, seed=123)\n",
    "\n",
    "finalDataset = DatasetDict({\"train\": trainData['train'], \n",
    "                                \"val\": valData['train'],\n",
    "                             \"test\": valData['test']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = finalDataset['train']['label']\n",
    "classWeights = compute_class_weight(class_weight= 'balanced', classes = np.unique(y), y=y)\n",
    "classWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0 :'Niets', 1 : 'Dehumaniserend', 2 : 'Demoniserend', 3 : '(Gewelds)bedreiging', 4: 'Doodsbedreiging'}\n",
    "label2id = {'Niets' : 0, 'Dehumaniserend' : 1 , 'Demoniserend' : 2, '(Gewelds)bedreiging' : 3, 'Doodsbedreiging' : 4}\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels=5, id2label=id2label, label2id = label2id)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "tokenizedDataset = finalDataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric= evaluate.load(\"f1\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')[\"precision\"]\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')[\"recall\"]\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')[\"f1\"]\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # You pass the class weights when instantiating the Trainer\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = None\n",
    "        outputs = model(**inputs)\n",
    "        # Save past state if it exists\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.label_smoother(outputs, labels)\n",
    "        else:\n",
    "            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "\n",
    "            # Changes start here\n",
    "            # loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "            logits = outputs['logits']\n",
    "            criterion = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            loss = criterion(logits, inputs['labels'])\n",
    "\n",
    "            # Changes end here\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=  tokenizedDataset['train'],\n",
    "    eval_dataset= tokenizedDataset['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=torch.tensor(classWeights,dtype=torch.float).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model=\"/path/to/classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"Test Sentence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
